{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5hE2k8eGlH8Y"
      },
      "outputs": [],
      "source": [
        "from glob import glob\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xqjY829ScQiy"
      },
      "outputs": [],
      "source": [
        "# this cell gets the training frame counts for the table used in the report\n",
        "# commented out for the run time though incase images are not downloaded to save space\n",
        "'''video_dir = \"../shanghaitech/training/videos/*/\"\n",
        "\n",
        "all_frames = {}\n",
        "for f in glob(f\"{video_dir}\"):\n",
        "  scene = f.split(\"/\")[-2].split('_')[0]\n",
        "  frames = len(glob(f + '*.jpg'))\n",
        "\n",
        "  try:\n",
        "    all_frames[scene] = all_frames[scene] + frames\n",
        "  except:\n",
        "    all_frames[scene] = frames'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lza0xvGMd2-g"
      },
      "outputs": [],
      "source": [
        "#all_frames_df = pd.DataFrame.from_dict(all_frames, orient='index', columns=['frames'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ApopW-lplL3d"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('./data/stc-train_tracked_poses_l.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "id": "slUVeK7G5bEq",
        "outputId": "df47cf39-6eaa-47fe-cd42-6b740a2c519f"
      },
      "outputs": [],
      "source": [
        "'''df['Scene'] = df['video'].apply(lambda x: x.split('_')[0])\n",
        "train_dets = df.groupby('Scene').personID.count()\n",
        "\n",
        "all_frames_df.rename(columns={'frames': 'Training frames'}, inplace=True)\n",
        "frame_counts = all_frames_df.merge(train_dets, left_index=True, right_index=True)\n",
        "frame_counts.rename(columns={'personID': 'Training detections'}, inplace=True)\n",
        "frame_counts['Train pose detections per frame'] = frame_counts['Training detections']/frame_counts['Training frames']\n",
        "frame_counts'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df['Scene'] = df['video'].apply(lambda x: x.split('_')[0])\n",
        "train_dets = df.groupby('Scene').personID.count()\n",
        "frame_counts = train_dets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8LocHGkMuVk"
      },
      "source": [
        "# VSA Encoding (TRAIN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r48nzM7cQKzF"
      },
      "outputs": [],
      "source": [
        "from src.vsa_encoding import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g1vbGTXcETNw"
      },
      "outputs": [],
      "source": [
        "scenes = sorted(list(set([id[:2] for id in df['video'].unique()])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3BHF1XIhPtAZ",
        "outputId": "7b896e6a-8d93-4c1b-c80a-e349c121c368"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "gc.collect()\n",
        "\n",
        "inference_components = {}\n",
        "\n",
        "d = 10000\n",
        "bins = 5\n",
        "\n",
        "\n",
        "Joints = hd.random(5,d)\n",
        "Speeds = hd.random(bins,d)\n",
        "Aspect = hd.random(bins,d)\n",
        "Pos = hd.random((bins*bins)+1,d)\n",
        "Times = hd.random(bins,d)\n",
        "Wrists = hd.random(5,d)\n",
        "Postures = hd.random(5, d)\n",
        "Features = hd.random(6,d)\n",
        "\n",
        "clusters = 10\n",
        "\n",
        "for scene in scenes:\n",
        "    print(f\"Processing scene: {scene}\")\n",
        "    detections = df[df['video'].str.startswith(scene)]\n",
        "\n",
        "    detections, aspect_thresh, time_thresh = build_encoding_df(detections, bins=bins, aspect_thresh=None, time_thresh=None)\n",
        "\n",
        "    vsa = encode_vsa(detections, Features, Pos, Aspect, Times, Postures, bins=bins)\n",
        "\n",
        "    temporal_vecs = build_temporal_enc(detections, vsa)\n",
        "    temporal_vecs = torch.stack(temporal_vecs)\n",
        "\n",
        "\n",
        "    prototypes, kmeans = cluster(temporal_vecs, clusters)\n",
        "\n",
        "    if kmeans is None:\n",
        "            labels = np.array([0]*len(temporal_vecs))\n",
        "    else:\n",
        "            labels = kmeans.labels_\n",
        "\n",
        "    thresholds = compute_cluster_thresholds(prototypes, temporal_vecs, labels)\n",
        "    fine_tuned_prototypes = fine_tune_prototypes(prototypes, temporal_vecs, labels)\n",
        "    thresholds = compute_cluster_thresholds(fine_tuned_prototypes, temporal_vecs, labels)\n",
        "\n",
        "\n",
        "    # Store only whatâ€™s needed\n",
        "    inference_components[scene] = (fine_tuned_prototypes, thresholds,\n",
        "                                   aspect_thresh, time_thresh)\n",
        "\n",
        "    # Free memory from intermediate steps\n",
        "    del detections, vsa, temporal_vecs, prototypes, kmeans, thresholds\n",
        "    gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j1D6CQz2QcpQ"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "with open('./data/shanghaitech/inference_components.pkl', 'wb') as f:\n",
        "    pickle.dump(inference_components, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SIcC4LhcVF5"
      },
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bafIEvPx8ElW"
      },
      "outputs": [],
      "source": [
        "test = pd.read_csv('./data/stc-test_tracked_poses_l.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MxW7zSeGP70p"
      },
      "outputs": [],
      "source": [
        "scenes = sorted(list(set([id for id in test['video'].unique()])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tjnAhf8PAIs0",
        "outputId": "7e984b68-8def-44d9-cd7f-17b39d0e98f1"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "import time\n",
        "\n",
        "gc.collect()\n",
        "\n",
        "preds = {}\n",
        "\n",
        "start = time.time()\n",
        "for scene in scenes:\n",
        "    print(f\"Processing scene: {scene}\")\n",
        "    test_detections = test[test['video'].str.startswith(scene)]\n",
        "\n",
        "    test_detections, _, _ = build_encoding_df(test_detections, aspect_thresh=aspect_thresh, time_thresh=time_thresh)\n",
        "    test_vsa = encode_vsa(test_detections, Features, Pos, Aspect, Times, Postures, bins=bins)\n",
        "\n",
        "    prototypes = inference_components.get(scene[:2])[0]\n",
        "    thresholds = inference_components.get(scene[:2])[1]\n",
        "    aspect_thresh = inference_components.get(scene[:2])[2]\n",
        "    time_thresh = inference_components.get(scene[:2])[3]\n",
        "\n",
        "    test_temporal_vecs = build_temporal_enc(test_detections, test_vsa)\n",
        "    test_temporal_vecs = torch.stack(test_temporal_vecs)\n",
        "\n",
        "    scores = evaluate_test_vectors(prototypes, thresholds, test_temporal_vecs)\n",
        "\n",
        "    preds[test_detections['video'].iloc[0]] = [scores, test_detections['frameID'].tolist()]\n",
        "\n",
        "    # Free memory from intermediate steps\n",
        "    del test_detections, test_vsa, test_temporal_vecs\n",
        "    gc.collect()\n",
        "\n",
        "end = time.time()\n",
        "\n",
        "latency = end - start\n",
        "\n",
        "latency"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gKvPRh2vAS15"
      },
      "outputs": [],
      "source": [
        "truth = pd.read_csv('./data/ShanghaiTech-Labels.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AUQCqdw28PQL"
      },
      "outputs": [],
      "source": [
        "truth['Scene'] = truth['Video'].apply(lambda row: row.split('_')[0])\n",
        "\n",
        "anomaly_counts = truth.groupby(['Scene', 'anomalyPresence']).Frame.count().reset_index()\n",
        "anomaly_counts = anomaly_counts.pivot(columns='anomalyPresence', index='Scene', values='Frame').reset_index()\n",
        "anomaly_counts.rename(columns={0:'No Anomaly', 1:'Anomaly'}, inplace=True)\n",
        "anomaly_counts.index = anomaly_counts['Scene']\n",
        "frame_counts = anomaly_counts.merge(frame_counts, left_index=True, right_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yq73DYwa-QQ1"
      },
      "outputs": [],
      "source": [
        "test['Scene'] = test['video'].apply(lambda row: row.split('_')[0])\n",
        "test_frames = test.groupby('Scene').personID.count().reset_index()\n",
        "test_frames.rename(columns={'personID': 'Test pose detections'}, inplace=True)\n",
        "test_frames.index = test_frames['Scene']\n",
        "frame_counts = frame_counts.merge(test_frames, left_index=True, right_index=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6oTuYFHT-E_"
      },
      "source": [
        "Morais et al (2019) filtering removes these frames for HR only anomalies (see written work for full citation)\n",
        "\n",
        "â€¢Camera 01: Videos 0130, 0135 and 0136;\n",
        "â€¢Camera 06: Videos 0144 and 0145;\n",
        "â€¢Camera 12: Video 0152."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "truth = truth[~truth['Video'].isin(['0130', '0135', '0136', '0144' '0145', '0152'])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "AKgR-UxEJfVW",
        "outputId": "aa01df51-5538-42e1-df6e-6835f14dfa03"
      },
      "outputs": [],
      "source": [
        "recs = []\n",
        "for k,p in preds.items():\n",
        "  scene = k\n",
        "  pred = p[0][0]\n",
        "  scores = p[0][1]\n",
        "  threshes = p[0][2]\n",
        "  frame = p[1]\n",
        "\n",
        "  for j, f in enumerate(frame):\n",
        "    rec = {\"vidID\": scene, \"frameID\": frame[j], \"AnomalyScore\": pred[j], \"Thresh\":threshes[j]}\n",
        "\n",
        "    recs.append(rec)\n",
        "\n",
        "all_res = pd.DataFrame(recs)\n",
        "all_res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PGU_KST5ONUQ"
      },
      "outputs": [],
      "source": [
        "results = all_res.groupby(['vidID', 'frameID']).agg({\n",
        "        'AnomalyScore': 'min',\n",
        "    }).reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2igBnGsduB3-"
      },
      "outputs": [],
      "source": [
        "truth['vidID'] = truth['Video']\n",
        "truth['frameID'] = truth['Frame']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eTh4EiD4OSTO"
      },
      "outputs": [],
      "source": [
        "results['vidID'] = results.apply(lambda row: row['vidID'].replace('_frames', ''), axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_dLBobPiOzFS"
      },
      "outputs": [],
      "source": [
        "comparison = truth.merge(results, on=['vidID', 'frameID'], how='left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "id": "zkyzCr99JCUh",
        "outputId": "86922eb7-7c91-4913-ff7d-277627a8ae57"
      },
      "outputs": [],
      "source": [
        "comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0GlbW9EvO0Qg",
        "outputId": "f7cf68de-3a9e-48fe-93fa-1a2776adc646"
      },
      "outputs": [],
      "source": [
        "# Ensure first NA becomes 0, then forward-fill within each video\n",
        "def custom_fill(group):\n",
        "    group = group.copy()\n",
        "    if pd.isna(group.iloc[0]['AnomalyScore']):\n",
        "        group.iloc[0, group.columns.get_loc('AnomalyScore')] = 1\n",
        "    group['AnomalyScore'] = group['AnomalyScore'].ffill()\n",
        "    return group\n",
        "\n",
        "comparison.sort_values(['vidID', 'frameID'], inplace=True)\n",
        "comparison = comparison.groupby('vidID', group_keys=False).apply(custom_fill)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bfgFUggxbTta"
      },
      "outputs": [],
      "source": [
        "comparison['smoothed_score'] = (\n",
        "    comparison\n",
        "    .sort_values(['vidID', 'frameID'])  # ensure correct order\n",
        "    .groupby('vidID')['AnomalyScore']\n",
        "    .transform(lambda x: x.rolling(window=25, center=True, min_periods=1).mean())\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hKW13kPnO9q-"
      },
      "outputs": [],
      "source": [
        "comparison['smoothed_score'] = comparison['smoothed_score'].apply(lambda x: 1-x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zDXKfZlpa5Eg",
        "outputId": "8d200a00-2730-41fe-bb7a-e159e81516fb"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_auc_score, roc_curve\n",
        "\n",
        "roc_auc_score(comparison['anomalyPresence'], comparison['smoothed_score'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RSdnL6oFifBu",
        "outputId": "b4d5db90-450d-4109-a18f-dcc784740835"
      },
      "outputs": [],
      "source": [
        "comparison.isna().sum()['AnomalyScore']/len(comparison)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZXEUl5oBURaQ"
      },
      "outputs": [],
      "source": [
        "comparison['Scene'] = comparison['Video'].apply(lambda x: x[:2])\n",
        "\n",
        "auc = {}\n",
        "\n",
        "for scene in comparison['Scene'].unique():\n",
        "  score = roc_auc_score(comparison[comparison['Scene'] == scene]['anomalyPresence'], comparison[comparison['Scene'] == scene]['smoothed_score'])\n",
        "\n",
        "  auc[scene] = score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JEhET7DfJPXb"
      },
      "outputs": [],
      "source": [
        "auc_df = pd.DataFrame(auc.items(), columns=['Scene', 'AUC'])\n",
        "auc_df.index = auc_df['Scene']\n",
        "auc_df.drop('Scene', axis=1, inplace=True)\n",
        "\n",
        "frame_counts = frame_counts.merge(auc_df, left_index=True, right_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 475
        },
        "id": "Gy0hYUWS_Zuz",
        "outputId": "1e794d44-50a4-4510-906e-14fedcf6000e"
      },
      "outputs": [],
      "source": [
        "frame_counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lHNUQgoV_R9a"
      },
      "outputs": [],
      "source": [
        "frame_counts['Test detections per frame'] = frame_counts.apply(lambda row: (row['Test pose detections'])/ (row['Anomaly'] + row['No Anomaly']), axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oiGsqYbk_LhK"
      },
      "outputs": [],
      "source": [
        "frame_counts.to_csv('data/shanghaitech/frame_corr_data.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_eiwsGPsUozX"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
