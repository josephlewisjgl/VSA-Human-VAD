{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Pose estimation\n",
        "\n",
        "This is a slight modification of the earlier pose estimation code to run on ShanghaiTech - it saves the outputs at intermediates incase of kernel crashes on the larger dataset.\n",
        "\n",
        "For the written work this was run in Google Colab, and advised to repeat there if you would like to verify the pose estimation.\n",
        "\n",
        "The pose estimation can be skipped by using the pre-extracted poses as outlined in the README."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PWP95KLsaRFd"
      },
      "outputs": [],
      "source": [
        "from glob import glob\n",
        "\n",
        "# incase of kernel crashes when running the pose estimator\n",
        "done = glob('data/shanghaitech/tracked_poses_l_shanghai_*.csv')\n",
        "done = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gcNdQLriadxK"
      },
      "outputs": [],
      "source": [
        "done = [[d[-17:-4] for d in done]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "NPYqqlA4shcF",
        "outputId": "4d1a4854-355f-49ed-e411-45d5d596c1f3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "from ultralytics import YOLO\n",
        "from src.sortalg import Sort\n",
        "\n",
        "model = YOLO(model = YOLO(\"yolo11l-pose.pt\"))\n",
        "\n",
        "results = []\n",
        "\n",
        "video_dir = \"../shanghaitech/training/videos\"\n",
        "\n",
        "for video_name in tqdm(os.listdir(video_dir)):\n",
        "    results = []\n",
        "\n",
        "    tracker = Sort(max_age=10)\n",
        "\n",
        "    if '_frames':\n",
        "        print(video_name)\n",
        "\n",
        "        frame_dir = os.path.join(video_dir, video_name)\n",
        "        if not os.path.isdir(frame_dir):\n",
        "            continue\n",
        "\n",
        "        frame_files = sorted(os.listdir(frame_dir))\n",
        "\n",
        "        for frame_idx, frame_file in enumerate(frame_files):\n",
        "            frame_path = os.path.join(frame_dir, frame_file)\n",
        "            frame = cv2.imread(frame_path)\n",
        "\n",
        "            pred = model.predict(source=frame, conf=0.1, save=False, verbose=False)\n",
        "            keypoints = pred[0].keypoints  \n",
        "            boxes = pred[0].boxes.xyxy.cpu().numpy()  \n",
        "            scores = pred[0].boxes.conf.cpu().numpy()  \n",
        "\n",
        "            if keypoints is None or len(keypoints) == 0:\n",
        "                continue\n",
        "\n",
        "            detections = []\n",
        "            for i in range(len(boxes)):\n",
        "                x1, y1, x2, y2 = boxes[i]\n",
        "                detections.append([x1, y1, x2, y2, scores[i]])\n",
        "            detections = np.array(detections)\n",
        "\n",
        "            tracked = tracker.update(detections)\n",
        "\n",
        "            for i, (x1, y1, x2, y2, track_id) in enumerate(tracked):\n",
        "                cx = (x1 + x2) / 2\n",
        "                cy = (y1 + y2) / 2\n",
        "                matched_idx = np.argmin([\n",
        "                    np.linalg.norm([(b[0] + b[2]) / 2 - cx, (b[1] + b[3]) / 2 - cy])\n",
        "                    for b in boxes\n",
        "                ])\n",
        "\n",
        "                kp = keypoints.data[matched_idx].cpu().numpy()\n",
        "                joints_flat = kp[:, :2].flatten()\n",
        "\n",
        "                row = {\n",
        "                    \"video\": video_name,\n",
        "                    \"frameID\": frame_idx,\n",
        "                    \"personID\": int(track_id),\n",
        "                    \"bbox_x1\": x1,\n",
        "                    \"bbox_y1\": y1,\n",
        "                    \"bbox_x2\": x2,\n",
        "                    \"bbox_y2\": y2\n",
        "                }\n",
        "                for j in range(17):\n",
        "                    row[f\"joint{j+1}x\"] = joints_flat[2 * j]\n",
        "                    row[f\"joint{j+1}y\"] = joints_flat[2 * j + 1]\n",
        "                results.append(row)\n",
        "\n",
        "\n",
        "        # Final save of all results\n",
        "        df = pd.DataFrame(results)\n",
        "        print(df)\n",
        "        df.to_csv(f\"data/shanghaitech/tracked_poses_l_shanghai_{video_name}.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9ZY5SnctPy_"
      },
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7F2M0L1oryi",
        "outputId": "134cfe29-1624-4d03-f045-d7bd089b94a3"
      },
      "outputs": [],
      "source": [
        "from glob import glob\n",
        "\n",
        "test_frames_dir = \"data/shanghaitech/testing/frames/\"\n",
        "\n",
        "done = glob('data/shanghaitech/test_poses_shanghai_l_*.csv')\n",
        "done = [d[-11:-4] for d in done]\n",
        "done"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_n0mfIHojp-",
        "outputId": "a607335a-35df-4e5b-dfd3-290855ef300b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "from ultralytics import YOLO\n",
        "from src.sortalg import Sort\n",
        "\n",
        "model = YOLO(model = YOLO(\"yolo11l-pose.pt\"))\n",
        "\n",
        "results = []\n",
        "\n",
        "video_dir = test_frames_dir\n",
        "for video_name in tqdm(os.listdir(video_dir)):\n",
        "    results = []\n",
        "\n",
        "    tracker = Sort(max_age=10)\n",
        "\n",
        "    if video_name not in done:\n",
        "        print(video_name)\n",
        "        frame_dir = os.path.join(video_dir, video_name)\n",
        "        if not os.path.isdir(frame_dir):\n",
        "            continue\n",
        "\n",
        "        frame_files = sorted(os.listdir(frame_dir))\n",
        "\n",
        "        for frame_idx, frame_file in enumerate(frame_files):\n",
        "            frame_path = os.path.join(frame_dir, frame_file)\n",
        "            frame = cv2.imread(frame_path)\n",
        "\n",
        "            pred = model.predict(source=frame, conf=0.1, save=False, verbose=False)\n",
        "            keypoints = pred[0].keypoints\n",
        "            boxes = pred[0].boxes.xyxy.cpu().numpy() \n",
        "            scores = pred[0].boxes.conf.cpu().numpy()\n",
        "\n",
        "            if keypoints is None or len(keypoints) == 0:\n",
        "                continue\n",
        "\n",
        "            detections = []\n",
        "            for i in range(len(boxes)):\n",
        "                x1, y1, x2, y2 = boxes[i]\n",
        "                detections.append([x1, y1, x2, y2, scores[i]])\n",
        "            detections = np.array(detections)\n",
        "\n",
        "            tracked = tracker.update(detections)\n",
        "\n",
        "            for i, (x1, y1, x2, y2, track_id) in enumerate(tracked):\n",
        "                cx = (x1 + x2) / 2\n",
        "                cy = (y1 + y2) / 2\n",
        "                matched_idx = np.argmin([\n",
        "                    np.linalg.norm([(b[0] + b[2]) / 2 - cx, (b[1] + b[3]) / 2 - cy])\n",
        "                    for b in boxes\n",
        "                ])\n",
        "\n",
        "                kp = keypoints.data[matched_idx].cpu().numpy()\n",
        "                joints_flat = kp[:, :2].flatten()\n",
        "\n",
        "                row = {\n",
        "                    \"video\": video_name,\n",
        "                    \"frameID\": frame_idx,\n",
        "                    \"personID\": int(track_id),\n",
        "                    \"bbox_x1\": x1,\n",
        "                    \"bbox_y1\": y1,\n",
        "                    \"bbox_x2\": x2,\n",
        "                    \"bbox_y2\": y2\n",
        "                }\n",
        "                for j in range(17):\n",
        "                    row[f\"joint{j+1}x\"] = joints_flat[2 * j]\n",
        "                    row[f\"joint{j+1}y\"] = joints_flat[2 * j + 1]\n",
        "                results.append(row)\n",
        "\n",
        "        # Final save of all results\n",
        "        df = pd.DataFrame(results)\n",
        "        df.to_csv(f\"/content/drive/My Drive/shanghaitech/test_poses_shanghai_l_{video_name}.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Combine extracted poses\n",
        "\n",
        "The code below combines the extracted poses into single CSVs like the ones provided by default in the repo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dfs = []\n",
        "for f in glob('data/shanghaitech/tracked_poses_l*_frames.csv'):\n",
        "  try:\n",
        "    dfs.append(pd.read_csv(f))\n",
        "  except:\n",
        "    print(f)\n",
        "\n",
        "df = pd.concat(dfs)\n",
        "del dfs\n",
        "\n",
        "df.to_csv('./data/stc-train_tracked_poses_l.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dfs = []\n",
        "for f in glob('data/shanghaitech/test_poses_shanghai_l*.csv'):\n",
        "  try:\n",
        "    dfs.append(pd.read_csv(f))\n",
        "  except:\n",
        "    print(f)\n",
        "\n",
        "df = pd.concat(dfs)\n",
        "del dfs\n",
        "\n",
        "df.to_csv('./data/stc-test_tracked_poses_l.csv')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
