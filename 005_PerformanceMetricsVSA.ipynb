{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "227458b6",
   "metadata": {},
   "source": [
    "# Results analysis for proposed VSA and Post-hoc systems\n",
    "\n",
    "Notebook for the performance analysis of VSA systems on edge device simulation + post-hoc system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce317f7",
   "metadata": {},
   "source": [
    "## Post Hoc system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e639e69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from glob import glob\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3684e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv('data/HR-Avenue-Labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ee2bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post processing function\n",
    "def forward_fill(group):\n",
    "    group = group.copy()\n",
    "    if pd.isna(group.iloc[0]['AnomalyScore']):\n",
    "        group.iloc[0, group.columns.get_loc('AnomalyScore')] = 1\n",
    "    group['AnomalyScore'] = group['AnomalyScore'].ffill()\n",
    "    return group\n",
    "\n",
    "def process_preds_to_comparison(results, labels, window_size=100):\n",
    "    results['vid'] = results['video'].apply(lambda r: r[:2]).astype(int)\n",
    "    labels['vid'] = labels['vid'].astype(int)\n",
    "    \n",
    "    anomaly_preds = results.groupby(['vid', 'frameID']).agg({\n",
    "        'AnomalyScore': 'min',\n",
    "    }).reset_index()\n",
    "\n",
    "    anomaly_preds = anomaly_preds.merge(results[['vid', 'frameID', 'AnomalyScore', 'AnomalyThreshold']], on=['vid', 'frameID', 'AnomalyScore'], how='left')\n",
    "    anomaly_preds.drop_duplicates(inplace=True)\n",
    "    comparison = anomaly_preds.merge(labels, how='right', \n",
    "                          right_on=['vid', 'Frame_ID'], \n",
    "                          left_on=['vid', 'frameID'])\n",
    "    \n",
    "    comparison.sort_values(['vid', 'Frame_ID'], inplace=True)\n",
    "    comparison = comparison.groupby('vid', group_keys=False).apply(forward_fill)\n",
    "    \n",
    "    comparison['AnomalyScore'] = comparison['AnomalyScore'].apply(lambda x: 1-x)\n",
    "    \n",
    "    comparison['AnomalyScore'] = (\n",
    "        comparison\n",
    "        .sort_values(['vid','frameID'])  # ensure correct order\n",
    "        .groupby(['vid'])['AnomalyScore']\n",
    "        .transform(lambda x: x.rolling(window=window_size, center=True, min_periods=1).mean())\n",
    "    )\n",
    "    \n",
    "    \n",
    "    comparison['SmoothedHDAnomaly'] = comparison.apply(lambda row: 1 if row['AnomalyScore'] > 1 - row['AnomalyThreshold'] else 0, axis=1)\n",
    "    \n",
    "    return comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b6efbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, auc, classification_report, confusion_matrix\n",
    "\n",
    "aucs = []\n",
    "for r in sorted(glob('data/results/results_posthocsystem_*[0-9].csv')):\n",
    "    if 'iso' not in r:\n",
    "        result= pd.read_csv(r)\n",
    "\n",
    "        \n",
    "        iteration = r.split('_')[-1].split('.')[0]\n",
    "\n",
    "        comparison = process_preds_to_comparison(result, labels, 25)\n",
    "\n",
    "        auc = roc_auc_score(comparison['Anomaly'], comparison['AnomalyScore'])\n",
    "        print(f\"Iteration: {iteration} AUC: {auc}\")\n",
    "\n",
    "        aucs.append(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f98fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Parameters\n",
    "confidence = 0.95\n",
    "n = len(aucs)\n",
    "mean = np.mean(aucs)\n",
    "sem = stats.sem(aucs)  # Standard Error of the Mean\n",
    "\n",
    "# Confidence interval\n",
    "h = sem * stats.t.ppf((1 + confidence) / 2, n - 1)\n",
    "ci_lower, ci_upper = mean - h, mean + h\n",
    "\n",
    "print(f\"Mean: {mean}\")\n",
    "print(f\"{confidence*100:.0f}% CI: ({ci_lower:.3f}, {ci_upper:.3f}), Error: {h}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9d6cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_mat_data = process_preds_to_comparison(pd.read_csv('./data/results/results_posthocsystem_' + str(np.argmax(aucs)) + '.csv'), labels, 25)\n",
    "conf_mat_post_hoc = confusion_matrix(confusion_mat_data['Anomaly'], confusion_mat_data['SmoothedHDAnomaly'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459e92bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "false_positive_rate = conf_mat_post_hoc[0,1] / (conf_mat_post_hoc[0,0] + conf_mat_post_hoc[0,1])\n",
    "false_negative_rate = conf_mat_post_hoc[1,0] / (conf_mat_post_hoc[1,0] + conf_mat_post_hoc[1,1])\n",
    "false_positive_rate, false_negative_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc732df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(confusion_mat_data['Anomaly'], \n",
    "                                             confusion_mat_data['SmoothedHDAnomaly']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b502b55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(confusion_mat_data['Anomaly'], confusion_mat_data['AnomalyScore'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50729eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_mat_data.to_csv('./data/results/best_posthoc.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a833a45",
   "metadata": {},
   "source": [
    "## Edge system performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a90beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "aucs = []\n",
    "for r in sorted(glob('./data/results/results_edgesystem_[0-9].csv')):\n",
    "    if 'iso' not in r:\n",
    "        result= pd.read_csv(r)\n",
    "\n",
    "        \n",
    "        iteration = r.split('_')[-2]\n",
    "\n",
    "        comparison = process_preds_to_comparison(result, labels, 10)\n",
    "\n",
    "        auc = roc_auc_score(comparison['Anomaly'], comparison['AnomalyScore'])\n",
    "        print(f\"Iteration: {iteration} AUC: {auc}\")\n",
    "\n",
    "        aucs.append(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa01900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "confidence = 0.95\n",
    "n = len(aucs)\n",
    "mean = np.mean(aucs)\n",
    "sem = stats.sem(aucs)  # Standard Error of the Mean\n",
    "\n",
    "# Confidence interval\n",
    "h = sem * stats.t.ppf((1 + confidence) / 2, n - 1)\n",
    "ci_lower, ci_upper = mean - h, mean + h\n",
    "\n",
    "print(f\"Mean: {mean}\")\n",
    "print(f\"{confidence*100:.0f}% CI: ({ci_lower:.3f}, {ci_upper:.3f}), Error: {h}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48dd8e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat_data = process_preds_to_comparison(pd.read_csv('./data/results/results_edgesystem_' + str(np.argmax(aucs)) + '.csv'), labels, 25)\n",
    "conf_mat = confusion_matrix(conf_mat_data['Anomaly'], conf_mat_data['SmoothedHDAnomaly'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5909d025",
   "metadata": {},
   "outputs": [],
   "source": [
    "false_positive_rate = conf_mat[0,1] / (conf_mat[0,0] + conf_mat[0,1])\n",
    "false_negative_rate = conf_mat[1,0] / (conf_mat[1,0] + conf_mat[1,1])\n",
    "false_positive_rate, false_negative_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6542648",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(conf_mat_data['Anomaly'], \n",
    "                    conf_mat_data['SmoothedHDAnomaly']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e84013",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat_data.to_csv('./data/results/best_edge.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd98e520",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "plt.rcParams[\"font.size\"] = 14\n",
    "\n",
    "# Create side-by-side subplots\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 7))\n",
    "\n",
    "# --- Left: Psthoc ---\n",
    "im = ax1.imshow(conf_mat_post_hoc, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "ax1.set_title(\"Posthoc System\", fontsize=20)\n",
    "\n",
    "tick_marks = np.arange(2)\n",
    "ax1.set_xticks(tick_marks)\n",
    "ax1.set_xticklabels([\"Normal\", \"Anomaly\"], fontsize=16)\n",
    "ax1.set_yticks(tick_marks)\n",
    "ax1.set_yticklabels([\"Normal\", \"Anomaly\"], fontsize=16)\n",
    "ax1.set_xlabel(\"Predicted label\", fontsize=18)\n",
    "ax1.set_ylabel(\"True label\", fontsize=18)\n",
    "\n",
    "# Add counts and proportions\n",
    "total = conf_mat_post_hoc.sum()\n",
    "for i in range(conf_mat_post_hoc.shape[0]):\n",
    "    for j in range(conf_mat_post_hoc.shape[1]):\n",
    "        count = conf_mat_post_hoc[i, j]\n",
    "        prop = count / total\n",
    "        ax1.text(j, i, f\"{count}\\n({prop:.2%})\",\n",
    "                 ha=\"center\", va=\"center\",\n",
    "                 color=\"white\" if count > conf_mat_post_hoc.max()/2 else \"black\",\n",
    "                 fontsize=18, fontweight=\"bold\")\n",
    "\n",
    "\n",
    "# --- Right: Edge Matrix ---\n",
    "im = ax2.imshow(conf_mat, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "ax2.set_title(\"Edge System\", fontsize=20)\n",
    "\n",
    "tick_marks = np.arange(2)\n",
    "ax2.set_xticks(tick_marks)\n",
    "ax2.set_xticklabels([\"Normal\", \"Anomaly\"], fontsize=16)\n",
    "ax2.set_yticks(tick_marks)\n",
    "ax2.set_yticklabels([\"Normal\", \"Anomaly\"], fontsize=16)\n",
    "ax2.set_xlabel(\"Predicted label\", fontsize=18)\n",
    "ax2.set_ylabel(\"True label\", fontsize=18)\n",
    "\n",
    "# Add counts and proportions\n",
    "total = conf_mat.sum()\n",
    "for i in range(conf_mat.shape[0]):\n",
    "    for j in range(conf_mat.shape[1]):\n",
    "        count = conf_mat[i, j]\n",
    "        prop = count / total\n",
    "        ax2.text(j, i, f\"{count}\\n({prop:.2%})\",\n",
    "                 ha=\"center\", va=\"center\",\n",
    "                 color=\"white\" if count > conf_mat.max()/2 else \"black\",\n",
    "                 fontsize=18, fontweight=\"bold\")\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15ad875",
   "metadata": {},
   "source": [
    "# Isolation Baseline\n",
    "\n",
    "The baseline isolation forest requires the same analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aadc728",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_preds_to_comparison_iso(results, labels, window_size=100):\n",
    "    results['vid'] = results['video'].apply(lambda r: r[:2]).astype(int)\n",
    "    labels['vid'] = labels['vid'].astype(int)\n",
    "    \n",
    "    anomaly_preds = results.groupby(['vid', 'frameID']).agg({\n",
    "        'AnomalyScore': 'min',\n",
    "    }).reset_index()\n",
    "\n",
    "    anomaly_preds = anomaly_preds.merge(results[['vid', 'frameID', 'AnomalyScore']], on=['vid', 'frameID', 'AnomalyScore'], how='left')\n",
    "    anomaly_preds.drop_duplicates(inplace=True)\n",
    "    comparison = anomaly_preds.merge(labels, how='right', \n",
    "                          right_on=['vid', 'Frame_ID'], \n",
    "                          left_on=['vid', 'frameID'])\n",
    "    \n",
    "    comparison.sort_values(['vid', 'Frame_ID'], inplace=True)\n",
    "    comparison = comparison.groupby('vid', group_keys=False).apply(forward_fill)\n",
    "    \n",
    "    comparison['AnomalyScore'] = comparison['AnomalyScore'].apply(lambda x: 1-x)\n",
    "    \n",
    "    comparison['AnomalyScore'] = (\n",
    "        comparison\n",
    "        .sort_values(['vid','frameID'])  # ensure correct order\n",
    "        .groupby(['vid'])['AnomalyScore']\n",
    "        .transform(lambda x: x.rolling(window=window_size, center=True, min_periods=1).mean())\n",
    "    )\n",
    "    \n",
    "        \n",
    "    return comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e940e57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pd.read_csv('./data/results/results_isoforest.csv')\n",
    "\n",
    "comparison = process_preds_to_comparison_iso(preds, labels, window_size=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3e1ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(comparison['Anomaly'], comparison['AnomalyScore'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27505157",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison.to_csv('data/results/best_isoforest.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
