{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abe14e5c",
   "metadata": {},
   "source": [
    "# Interpretability examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb03fce",
   "metadata": {},
   "source": [
    "This notebook demonstrates interpretability by decomposing vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fadceafd",
   "metadata": {},
   "source": [
    "## Perform training and inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48208952",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joelewis/Desktop/Dissertation/NeuroSymbol-CUHK/vsa_encoding.py:212: RuntimeWarning: invalid value encountered in divide\n",
      "  cos_theta = np.sum(ba * bc, axis=1) / (np.linalg.norm(ba, axis=1) * np.linalg.norm(bc, axis=1))\n",
      "/Users/joelewis/Desktop/Dissertation/NeuroSymbol-CUHK/vsa_encoding.py:244: RuntimeWarning: All-NaN axis encountered\n",
      "  knee_angle = np.nanmax([l_angle, r_angle], axis=0)\n",
      "100%|██████████| 89313/89313 [00:05<00:00, 15445.20it/s]\n",
      "89313it [00:08, 10640.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 10000]) <class 'numpy.ndarray'>\n",
      "Prototypes finetuned\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joelewis/Desktop/Dissertation/NeuroSymbol-CUHK/vsa_encoding.py:212: RuntimeWarning: invalid value encountered in divide\n",
      "  cos_theta = np.sum(ba * bc, axis=1) / (np.linalg.norm(ba, axis=1) * np.linalg.norm(bc, axis=1))\n",
      "/Users/joelewis/Desktop/Dissertation/NeuroSymbol-CUHK/vsa_encoding.py:244: RuntimeWarning: All-NaN axis encountered\n",
      "  knee_angle = np.nanmax([l_angle, r_angle], axis=0)\n",
      "100%|██████████| 85747/85747 [00:05<00:00, 14611.94it/s]\n",
      "85747it [00:07, 10846.61it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torchhd as hd\n",
    "import torch\n",
    "\n",
    "import gc\n",
    "\n",
    "from src.vsa_encoding import *\n",
    "\n",
    "temporal = True\n",
    "d = 10000\n",
    "bins = 3\n",
    "clusters = 10\n",
    "\n",
    "\n",
    "for i in range(1):\n",
    "    \n",
    "    Joints = hd.random(5,d)\n",
    "    Speeds = hd.random(bins,d)\n",
    "    Aspect = hd.random(bins,d)\n",
    "    Pos = hd.random(bins*bins+1,d)\n",
    "    Times = hd.random(bins,d)\n",
    "    Wrists = hd.random(5,d)\n",
    "    Postures = hd.random(5, d)\n",
    "    Features = hd.random(6,d)\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "    inference_components = {}\n",
    "\n",
    "    df = pd.read_csv('./tracked_poses_s.csv')\n",
    "\n",
    "    detections, aspect_thresh, time_thresh = build_encoding_df(df, bins=bins, aspect_thresh=None, time_thresh=None)\n",
    "\n",
    "    vsa = encode_vsa(detections, Features, Pos, Aspect, Times, Postures, bins=bins)\n",
    "\n",
    "    if temporal:\n",
    "        temporal_vecs = build_temporal_enc(detections, vsa)\n",
    "        temporal_vecs = torch.stack(temporal_vecs)\n",
    "    else:\n",
    "        temporal_vecs = torch.stack(vsa)\n",
    "\n",
    "    prototypes, kmeans = cluster(temporal_vecs, clusters)\n",
    "\n",
    "    if kmeans is None:\n",
    "        labels = np.array([0] * len(temporal_vecs))\n",
    "    else:\n",
    "        labels = kmeans.labels_\n",
    "\n",
    "    print(prototypes.shape, type(labels))\n",
    "\n",
    "    thresholds = compute_cluster_thresholds(prototypes, temporal_vecs, labels)\n",
    "    fine_tuned_prototypes = fine_tune_prototypes(prototypes, temporal_vecs, labels)\n",
    "    updated_thresholds = compute_cluster_thresholds(fine_tuned_prototypes, temporal_vecs, labels)\n",
    "\n",
    "    print('Prototypes finetuned')\n",
    "\n",
    "    test = pd.read_csv('./test_tracked_poses_m.csv')\n",
    "    test_detections, _,  _ = build_encoding_df(test, aspect_thresh=aspect_thresh, time_thresh=time_thresh)\n",
    "    test_vsa = encode_vsa(test_detections, Features, Pos, Aspect, Times, Postures, bins=bins)\n",
    "    if temporal:\n",
    "        test_temporal_vecs = build_temporal_enc(test_detections, test_vsa)\n",
    "        test_temporal_vecs = torch.stack(test_temporal_vecs)\n",
    "\n",
    "    else:\n",
    "        test_temporal_vecs = torch.stack(test_vsa)\n",
    "\n",
    "    results = evaluate_test_vectors(fine_tuned_prototypes, updated_thresholds, test_temporal_vecs)\n",
    "\n",
    "    results = pd.DataFrame({\n",
    "        'video': test_detections['video'],\n",
    "        'personID': test_detections['personID'],\n",
    "        'frameID': test_detections['frameID'],\n",
    "        'AnomalyScore': results[0],\n",
    "        'AnomalyLabel': results[1],\n",
    "        'AnomalyThreshold': results[2],\n",
    "        'RandomSeed': seed,\n",
    "        'Iteration': i\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc06605",
   "metadata": {},
   "source": [
    "## Example One: Video 21 - Child running near camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "96c25aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "interp_test = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "4b96d3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "interp_test['video'] = interp_test.apply(lambda row: int(row['video'].split('_')[0]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "0c41db6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "interp_test['VecIndex'] = interp_test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "30e4c565",
   "metadata": {},
   "outputs": [],
   "source": [
    "at_t_00 = interp_test[(interp_test['frameID'] == 0) & (interp_test['personID'] == 1913) & (interp_test['video'] == 21)]\n",
    "at_t_20 = interp_test[(interp_test['frameID'] ==  20) & (interp_test['personID'] == 1913) & (interp_test['video'] == 21)]\n",
    "at_t_40 = interp_test[(interp_test['frameID'] ==  40) & (interp_test['personID'] == 1913) & (interp_test['video'] == 21)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "8fdd8f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_at_00 = test_temporal_vecs[at_t_00.index]\n",
    "vec_at_20 = test_temporal_vecs[at_t_20['VecIndex'].dropna().to_numpy()]\n",
    "vec_at_40 = test_temporal_vecs[at_t_40['VecIndex'].dropna().to_numpy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "8e1f1182",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(MAPTensor([[-1., -1., -1.,  ...,  1.,  1.,  1.]]),\n",
       " MAPTensor([[ 1., -1., -1.,  ..., -1.,  1., -1.]]),\n",
       " MAPTensor([[-1., -1., -1.,  ...,  1.,  1.,  1.]]))"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closest_prototype_00 = fine_tuned_prototypes[hd.cosine_similarity(vec_at_00, fine_tuned_prototypes).argmax(dim=1)]\n",
    "closest_prototype_20 = fine_tuned_prototypes[hd.cosine_similarity(vec_at_20, fine_tuned_prototypes).argmax(dim=1)]\n",
    "closest_prototype_40 = fine_tuned_prototypes[hd.cosine_similarity(vec_at_40, fine_tuned_prototypes).argmax(dim=1)]\n",
    "closest_prototype_00, closest_prototype_20, closest_prototype_40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "223d0c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe prototypes that are closest\n",
    "aspect_labels = ['far', 'middle', 'close']\n",
    "time_labels = ['short', 'normal', 'long']\n",
    "posture_labels = ['crouching', 'standing', 'leaning', 'unknown', 'sitting']\n",
    "\n",
    "def interpret_vec(vec):\n",
    "    aspect = aspect_labels[np.argmax(hd.cosine_similarity(hd.bind(Features[2], vec), Aspect))]\n",
    "    posture = posture_labels[np.argmax(hd.cosine_similarity(hd.bind(Features[3], vec), Postures))]\n",
    "    time = time_labels[np.argmax(hd.cosine_similarity(hd.bind(Features[0], vec), Times))]\n",
    "    position = np.argmax(hd.cosine_similarity(hd.bind(Features[1], vec), Pos)).item()\n",
    "    \n",
    "    print(f\"Vector: Aspect: {aspect}, Time: {time}, Position:{position}, Posture: {posture}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "f3b3e179",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video</th>\n",
       "      <th>personID</th>\n",
       "      <th>frameID</th>\n",
       "      <th>AnomalyScore</th>\n",
       "      <th>AnomalyLabel</th>\n",
       "      <th>AnomalyThreshold</th>\n",
       "      <th>RandomSeed</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>VecIndex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>85231</th>\n",
       "      <td>21</td>\n",
       "      <td>1913</td>\n",
       "      <td>0</td>\n",
       "      <td>0.499768</td>\n",
       "      <td>MAPTensor(True)</td>\n",
       "      <td>0.606167</td>\n",
       "      <td>2993</td>\n",
       "      <td>0</td>\n",
       "      <td>85231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       video  personID  frameID  AnomalyScore     AnomalyLabel  \\\n",
       "85231     21      1913        0      0.499768  MAPTensor(True)   \n",
       "\n",
       "       AnomalyThreshold  RandomSeed  Iteration  VecIndex  \n",
       "85231          0.606167        2993          0     85231  "
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interp_test[(interp_test['video'] == 21) & (interp_test['personID'] == 1913) & (interp_test['frameID'] == 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "ff037710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector: Aspect: close, Time: short, Position:6, Posture: standing\n"
     ]
    }
   ],
   "source": [
    "interpret_vec(vec_at_00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "1f18d731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector: Aspect: middle, Time: short, Position:5, Posture: standing\n"
     ]
    }
   ],
   "source": [
    "interpret_vec(closest_prototype_00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "daaf9082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video</th>\n",
       "      <th>personID</th>\n",
       "      <th>frameID</th>\n",
       "      <th>AnomalyScore</th>\n",
       "      <th>AnomalyLabel</th>\n",
       "      <th>AnomalyThreshold</th>\n",
       "      <th>RandomSeed</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>VecIndex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>85251</th>\n",
       "      <td>21</td>\n",
       "      <td>1913</td>\n",
       "      <td>20</td>\n",
       "      <td>0.315072</td>\n",
       "      <td>MAPTensor(True)</td>\n",
       "      <td>0.714812</td>\n",
       "      <td>2993</td>\n",
       "      <td>0</td>\n",
       "      <td>85251</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       video  personID  frameID  AnomalyScore     AnomalyLabel  \\\n",
       "85251     21      1913       20      0.315072  MAPTensor(True)   \n",
       "\n",
       "       AnomalyThreshold  RandomSeed  Iteration  VecIndex  \n",
       "85251          0.714812        2993          0     85251  "
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[(results['video'] == 21) & (results['frameID'] ==20) & (results['personID'] == 1913)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "56952630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector: Aspect: close, Time: short, Position:5, Posture: unknown\n"
     ]
    }
   ],
   "source": [
    "interpret_vec(vec_at_20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "ba61e87d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector: Aspect: middle, Time: short, Position:1, Posture: unknown\n"
     ]
    }
   ],
   "source": [
    "interpret_vec(closest_prototype_20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "7d09b730",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video</th>\n",
       "      <th>personID</th>\n",
       "      <th>frameID</th>\n",
       "      <th>AnomalyScore</th>\n",
       "      <th>AnomalyLabel</th>\n",
       "      <th>AnomalyThreshold</th>\n",
       "      <th>RandomSeed</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>VecIndex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>85271</th>\n",
       "      <td>21</td>\n",
       "      <td>1913</td>\n",
       "      <td>40</td>\n",
       "      <td>0.26071</td>\n",
       "      <td>MAPTensor(True)</td>\n",
       "      <td>0.547292</td>\n",
       "      <td>2993</td>\n",
       "      <td>0</td>\n",
       "      <td>85271</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       video  personID  frameID  AnomalyScore     AnomalyLabel  \\\n",
       "85271     21      1913       40       0.26071  MAPTensor(True)   \n",
       "\n",
       "       AnomalyThreshold  RandomSeed  Iteration  VecIndex  \n",
       "85271          0.547292        2993          0     85271  "
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[(results['video'] == 21) & (results['frameID'] ==40) & (results['personID'] == 1913)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "bbf803ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector: Aspect: close, Time: normal, Position:5, Posture: leaning\n"
     ]
    }
   ],
   "source": [
    "interpret_vec(vec_at_40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "62bdac17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector: Aspect: middle, Time: normal, Position:2, Posture: standing\n"
     ]
    }
   ],
   "source": [
    "interpret_vec(closest_prototype_40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08bb67e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector: Aspect: close, Time: long, Position:8, Posture: unknown\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "interpret_vec(hd.permute(vec_at_40, shifts=-2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac17e89",
   "metadata": {},
   "source": [
    "## Example 2: Man running across scene\n",
    "\n",
    "Described at frame level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "f821ddee",
   "metadata": {},
   "outputs": [],
   "source": [
    "at_t_580 = interp_test[(interp_test['frameID'] == 580) & (interp_test['personID'] == 1145) & (interp_test['video'] == 3)]\n",
    "at_t_610 = interp_test[(interp_test['frameID'] == 610) & (interp_test['personID'] == 1162) & (interp_test['video'] == 3)]\n",
    "at_t_640 = interp_test[(interp_test['frameID'] == 640) & (interp_test['personID'] == 1165) & (interp_test['video'] == 3)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "a5cce9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_at_580 = test_temporal_vecs[at_t_580.index]\n",
    "vec_at_610 = test_temporal_vecs[at_t_610.index]\n",
    "vec_at_640 = test_temporal_vecs[at_t_640.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "b2c6507c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(MAPTensor([[1., 1., 1.,  ..., 1., 1., 1.]]),\n",
       " MAPTensor([[ 1., -1., -1.,  ...,  1.,  1.,  1.]]),\n",
       " MAPTensor([[-1., -1., -1.,  ...,  1.,  1.,  1.]]))"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closest_prototype_580 = fine_tuned_prototypes[hd.cosine_similarity(vec_at_580, fine_tuned_prototypes).argmax(dim=1)]\n",
    "closest_prototype_610 = fine_tuned_prototypes[hd.cosine_similarity(vec_at_610, fine_tuned_prototypes).argmax(dim=1)]\n",
    "closest_prototype_640 = fine_tuned_prototypes[hd.cosine_similarity(vec_at_640, fine_tuned_prototypes).argmax(dim=1)]\n",
    "closest_prototype_580, closest_prototype_610, closest_prototype_640"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "08a609aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video</th>\n",
       "      <th>personID</th>\n",
       "      <th>frameID</th>\n",
       "      <th>AnomalyScore</th>\n",
       "      <th>AnomalyLabel</th>\n",
       "      <th>AnomalyThreshold</th>\n",
       "      <th>RandomSeed</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>VecIndex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18485</th>\n",
       "      <td>3</td>\n",
       "      <td>1145</td>\n",
       "      <td>580</td>\n",
       "      <td>0.712279</td>\n",
       "      <td>MAPTensor(False)</td>\n",
       "      <td>0.499652</td>\n",
       "      <td>2993</td>\n",
       "      <td>0</td>\n",
       "      <td>18485</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       video  personID  frameID  AnomalyScore      AnomalyLabel  \\\n",
       "18485      3      1145      580      0.712279  MAPTensor(False)   \n",
       "\n",
       "       AnomalyThreshold  RandomSeed  Iteration  VecIndex  \n",
       "18485          0.499652        2993          0     18485  "
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "at_t_580"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "84e61899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector: Aspect: middle, Time: long, Position:2, Posture: standing\n"
     ]
    }
   ],
   "source": [
    "interpret_vec(vec_at_580)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "61923dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector: Aspect: middle, Time: long, Position:2, Posture: standing\n"
     ]
    }
   ],
   "source": [
    "interpret_vec(closest_prototype_580)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "801cf67e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video</th>\n",
       "      <th>personID</th>\n",
       "      <th>frameID</th>\n",
       "      <th>AnomalyScore</th>\n",
       "      <th>AnomalyLabel</th>\n",
       "      <th>AnomalyThreshold</th>\n",
       "      <th>RandomSeed</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>VecIndex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19058</th>\n",
       "      <td>3</td>\n",
       "      <td>1162</td>\n",
       "      <td>610</td>\n",
       "      <td>0.300814</td>\n",
       "      <td>MAPTensor(True)</td>\n",
       "      <td>0.55548</td>\n",
       "      <td>2993</td>\n",
       "      <td>0</td>\n",
       "      <td>19058</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       video  personID  frameID  AnomalyScore     AnomalyLabel  \\\n",
       "19058      3      1162      610      0.300814  MAPTensor(True)   \n",
       "\n",
       "       AnomalyThreshold  RandomSeed  Iteration  VecIndex  \n",
       "19058           0.55548        2993          0     19058  "
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "at_t_610"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "14dd26ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector: Aspect: close, Time: short, Position:5, Posture: unknown\n"
     ]
    }
   ],
   "source": [
    "interpret_vec(vec_at_610)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "c7a570af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector: Aspect: middle, Time: short, Position:2, Posture: standing\n"
     ]
    }
   ],
   "source": [
    "interpret_vec(closest_prototype_610)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "8aa8fdbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video</th>\n",
       "      <th>personID</th>\n",
       "      <th>frameID</th>\n",
       "      <th>AnomalyScore</th>\n",
       "      <th>AnomalyLabel</th>\n",
       "      <th>AnomalyThreshold</th>\n",
       "      <th>RandomSeed</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>VecIndex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19364</th>\n",
       "      <td>3</td>\n",
       "      <td>1165</td>\n",
       "      <td>640</td>\n",
       "      <td>0.816047</td>\n",
       "      <td>MAPTensor(False)</td>\n",
       "      <td>0.583249</td>\n",
       "      <td>2993</td>\n",
       "      <td>0</td>\n",
       "      <td>19364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       video  personID  frameID  AnomalyScore      AnomalyLabel  \\\n",
       "19364      3      1165      640      0.816047  MAPTensor(False)   \n",
       "\n",
       "       AnomalyThreshold  RandomSeed  Iteration  VecIndex  \n",
       "19364          0.583249        2993          0     19364  "
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "at_t_640"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "617c77a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector: Aspect: middle, Time: normal, Position:1, Posture: standing\n"
     ]
    }
   ],
   "source": [
    "interpret_vec(vec_at_640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "6378d95e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector: Aspect: middle, Time: normal, Position:1, Posture: standing\n"
     ]
    }
   ],
   "source": [
    "interpret_vec(closest_prototype_640)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10415487",
   "metadata": {},
   "source": [
    "## Example 3: Man walking wrong way\n",
    "\n",
    "Highlights system sensitivity to aspect feature and ability to diagnose problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "fbc12422",
   "metadata": {},
   "outputs": [],
   "source": [
    "at_t_100 = interp_test[(interp_test['frameID'] == 100) & (interp_test['personID'] == 435) & (interp_test['video'] == 6)] \n",
    "at_t_200 = interp_test[(interp_test['frameID'] == 200) & (interp_test['personID'] == 435) & (interp_test['video'] == 6)] \n",
    "at_t_300 = interp_test[(interp_test['frameID'] == 300) & (interp_test['personID'] == 435) & (interp_test['video'] == 6)] \n",
    "at_t_400 = interp_test[(interp_test['frameID'] == 400) & (interp_test['personID'] == 435) & (interp_test['video'] == 6)] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "3034631c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_at_100 = test_temporal_vecs[at_t_100.index]\n",
    "vec_at_200 = test_temporal_vecs[at_t_200.index]\n",
    "vec_at_300 = test_temporal_vecs[at_t_300.index]\n",
    "vec_at_400 = test_temporal_vecs[at_t_400.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "5df101fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(MAPTensor([[ 1., -1., -1.,  ...,  1.,  1.,  1.]]),\n",
       " MAPTensor([[1., 1., 1.,  ..., 1., 1., 1.]]),\n",
       " MAPTensor([[1., 1., 1.,  ..., 1., 1., 1.]]))"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closest_prototype_100 = fine_tuned_prototypes[hd.cosine_similarity(vec_at_100, fine_tuned_prototypes).argmax(dim=1)]\n",
    "closest_prototype_200 = fine_tuned_prototypes[hd.cosine_similarity(vec_at_200, fine_tuned_prototypes).argmax(dim=1)]\n",
    "closest_prototype_300 = fine_tuned_prototypes[hd.cosine_similarity(vec_at_300, fine_tuned_prototypes).argmax(dim=1)]\n",
    "closest_prototype_400 = fine_tuned_prototypes[hd.cosine_similarity(vec_at_400, fine_tuned_prototypes).argmax(dim=1)]\n",
    "\n",
    "closest_prototype_100, closest_prototype_200, closest_prototype_300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "2427ab7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video</th>\n",
       "      <th>personID</th>\n",
       "      <th>frameID</th>\n",
       "      <th>AnomalyScore</th>\n",
       "      <th>AnomalyLabel</th>\n",
       "      <th>AnomalyThreshold</th>\n",
       "      <th>RandomSeed</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>VecIndex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30145</th>\n",
       "      <td>6</td>\n",
       "      <td>435</td>\n",
       "      <td>100</td>\n",
       "      <td>0.69669</td>\n",
       "      <td>MAPTensor(False)</td>\n",
       "      <td>0.450879</td>\n",
       "      <td>2993</td>\n",
       "      <td>0</td>\n",
       "      <td>30145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       video  personID  frameID  AnomalyScore      AnomalyLabel  \\\n",
       "30145      6       435      100       0.69669  MAPTensor(False)   \n",
       "\n",
       "       AnomalyThreshold  RandomSeed  Iteration  VecIndex  \n",
       "30145          0.450879        2993          0     30145  "
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "at_t_100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "1f7766e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video</th>\n",
       "      <th>personID</th>\n",
       "      <th>frameID</th>\n",
       "      <th>AnomalyScore</th>\n",
       "      <th>AnomalyLabel</th>\n",
       "      <th>AnomalyThreshold</th>\n",
       "      <th>RandomSeed</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>VecIndex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30245</th>\n",
       "      <td>6</td>\n",
       "      <td>435</td>\n",
       "      <td>200</td>\n",
       "      <td>0.506304</td>\n",
       "      <td>MAPTensor(False)</td>\n",
       "      <td>0.499652</td>\n",
       "      <td>2993</td>\n",
       "      <td>0</td>\n",
       "      <td>30245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       video  personID  frameID  AnomalyScore      AnomalyLabel  \\\n",
       "30245      6       435      200      0.506304  MAPTensor(False)   \n",
       "\n",
       "       AnomalyThreshold  RandomSeed  Iteration  VecIndex  \n",
       "30245          0.499652        2993          0     30245  "
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "at_t_200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "e32a3005",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video</th>\n",
       "      <th>personID</th>\n",
       "      <th>frameID</th>\n",
       "      <th>AnomalyScore</th>\n",
       "      <th>AnomalyLabel</th>\n",
       "      <th>AnomalyThreshold</th>\n",
       "      <th>RandomSeed</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>VecIndex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30345</th>\n",
       "      <td>6</td>\n",
       "      <td>435</td>\n",
       "      <td>300</td>\n",
       "      <td>0.436718</td>\n",
       "      <td>MAPTensor(True)</td>\n",
       "      <td>0.499652</td>\n",
       "      <td>2993</td>\n",
       "      <td>0</td>\n",
       "      <td>30345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       video  personID  frameID  AnomalyScore     AnomalyLabel  \\\n",
       "30345      6       435      300      0.436718  MAPTensor(True)   \n",
       "\n",
       "       AnomalyThreshold  RandomSeed  Iteration  VecIndex  \n",
       "30345          0.499652        2993          0     30345  "
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "at_t_300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "3d419b58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video</th>\n",
       "      <th>personID</th>\n",
       "      <th>frameID</th>\n",
       "      <th>AnomalyScore</th>\n",
       "      <th>AnomalyLabel</th>\n",
       "      <th>AnomalyThreshold</th>\n",
       "      <th>RandomSeed</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>VecIndex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30445</th>\n",
       "      <td>6</td>\n",
       "      <td>435</td>\n",
       "      <td>400</td>\n",
       "      <td>0.436718</td>\n",
       "      <td>MAPTensor(True)</td>\n",
       "      <td>0.499652</td>\n",
       "      <td>2993</td>\n",
       "      <td>0</td>\n",
       "      <td>30445</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       video  personID  frameID  AnomalyScore     AnomalyLabel  \\\n",
       "30445      6       435      400      0.436718  MAPTensor(True)   \n",
       "\n",
       "       AnomalyThreshold  RandomSeed  Iteration  VecIndex  \n",
       "30445          0.499652        2993          0     30445  "
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "at_t_400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "beda16e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector: Aspect: middle, Time: normal, Position:5, Posture: standing\n"
     ]
    }
   ],
   "source": [
    "interpret_vec(vec_at_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "9fe091cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector: Aspect: middle, Time: normal, Position:2, Posture: standing\n"
     ]
    }
   ],
   "source": [
    "interpret_vec(closest_prototype_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "a89bc882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector: Aspect: close, Time: long, Position:6, Posture: standing\n"
     ]
    }
   ],
   "source": [
    "interpret_vec(vec_at_200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "08fd9684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector: Aspect: middle, Time: long, Position:2, Posture: standing\n"
     ]
    }
   ],
   "source": [
    "interpret_vec(closest_prototype_200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "5bbe814f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector: Aspect: close, Time: long, Position:6, Posture: standing\n"
     ]
    }
   ],
   "source": [
    "interpret_vec(vec_at_300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "b02d7631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector: Aspect: middle, Time: long, Position:2, Posture: standing\n"
     ]
    }
   ],
   "source": [
    "interpret_vec(closest_prototype_300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "c7ebf559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector: Aspect: close, Time: long, Position:6, Posture: standing\n"
     ]
    }
   ],
   "source": [
    "interpret_vec(vec_at_400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "00fd6699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector: Aspect: middle, Time: long, Position:2, Posture: standing\n"
     ]
    }
   ],
   "source": [
    "interpret_vec(closest_prototype_400)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
